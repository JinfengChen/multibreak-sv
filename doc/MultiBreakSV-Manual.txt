Manual for MultiBreak-SV

Software that identifies structural variants from next-generation paired end data, third-generation long read data, or data from a combination of sequencing platforms.

If you use MultiBreak-SV in your research, please cite:

A. Ritz, A. Bashir, S. Sindi, D. Hsu, I. Hajirasouliha, and B. J. Raphael. Characterization of Structural Variants with Single Molecule and Hybrid Sequencing Approaches, .

contact: Anna Ritz (annaritz@vt.edu)
contact: Ben Raphael (braphael@cs.brown.edu)

Beta Version 0.01
Version Date: December 2014

Table of Contents
#############################################################################
## I. Installation
## II. Pre-Processor Usage Instructions
##  (a). Input and Output Files
##  (b). Example Run
## III. MultiBreak-SV Usage Instructions
##  (a). Input Files
##  (b). Output Files
##  (c). Example Runs
## IV. Running MultiBreak-SV as Separate Subproblems
##  (a). generateIndependentSubproblems.pl Script
##  (b). Example Runs
## V. Additional Notes
#############################################################################

## I. Installation ##########################################################

Dependencies: Tested in Linux.  

(i) Java (tested on version 1.7)
(ii) Perl (tested on version 1.7)
(iii) Python (tested on version 2.7), including the following modules:
 - optparse, sys, os, subprocess, bisect, re, numpy, pysam, cython
(iv) GASV to cluster discordant pairs (https://code.google.com/p/gasv/).  
Download and note the install location.

Installation Instructions:

(i) Obtain the most recent version of MultiBreak-SV:

	git clone https://github.com/raphael-group/multibreak-sv.git

(ii) Install the code. Run the following command

     	./install 

     This will compile the Java and will create the following executables:

     	bin/M5toMBSV.py: Preprocessing python script
    	bin/ExternalSort.jar: sorting jarfile used by M5toMBSV.py
        bin/MultiBreakSV.jar: MultiBreak-SV java jarfile

(iii) Add the the lib/ directory to your PATH and PYTHONPATH environment variables.
In your ~/.bashrc script, copy the two lines output by the install script.

export PATH=$PATH:path/to/lib/
export PYTHONPATH=$PYTHONPATH:path/to/lib/

Then run the ~/.bashrc script by typing 'source ~/.bashrc'.  Alternatively, 
you can simply execute the export commands within the terminal to set the
environment variables for a single session.

(iii) Troubleshooting:
 - Windows does not have an 'env.PATH' ant variable: this is renamed to 'env.Path'.  
This must be modified in the build.xml file.

#############################################################################
## II. Pre-Processor Usage Instructions
#############################################################################

bin/M5toMBSV.py processes a machineformat (.m5) BLASR file by executing a series
of steps.  Briefly, they include:
(1) IDENTIFYING CONCORDANT ALIGNMENTS
  - remove nearly-full (within 80%) alignments.
  - this step is rather aggressive, and appropriate for high-coverage and/or
  whole-genome analyses.
  - see the '--keepconcord' option to ignore this step.
(2) FORMATTING FILES
  - rename reads to a more readable naming scheme.
  - convert file from m5 to a more readable format.
(3) GETTING MULTI-BREAKPOINT MAPPINGS
  - "piece" together partial alignments to generate multi-breakpoint-mappings
(4) MAKING ESP FILE
  - From multi-breakpoint mappings, generate end-sequence pair (ESP) file
  - GASV uses this type of file.
(5) CALCULATING AND ADDING DELETED REGIONS FROM HMM
  - Use the HMM to refine deletion breakpionts in the original m5 file
  - Add these as candidate deletions to the ESP file
  - This step may take a while; if the HMM output file exists, it is
  not overwritten.
(6) SPLITTING ESP FILE
  - GASV requires an Lmin/Lmax, which changes depending on the fragment size.
  - "Bin" the ESPs into different Lmin/Lmax regions.
(7) WRITING ASSIGNMENT FILE
  - Write the assignment file of subreads. Input for MultiBreak-SV.
(8) MAKING EXPERIMENT FILE
  - Write the experiment file. Input for MultiBreak-SV.
(9) RUNNING GASV
  - Run GASV on the binned ESP files.  Clusters are input to MultiBreak-SV.
(10) SPLITTING CLUSTERS FILE FOR MBSV
  - Divides the gasv.in.clusters file into independent subproblems.  
  - Allows for easy parallelization.

To print the usage, type 'python bin/M5toMBSV.py -h'. You will see
the following. Note that both a path to gasv and an .m5 file are required.

Usage: M5toMBSV.py [options] <path-to-gasv> <file.m5>

	path-to-gasv: root directory of GASV installation, 
		e.g., <path-to-gasv>/gasv-read-only/. 
		Necessary because scripts/sortPR.bash and bin/GASV.jar
		are called in this script.
	file.m5: required pacbio alignment file (m5 format).

Options:
  -h, --help            show this help message and exit
  --prefix=PREFIX       String to prepend to all output files. Default =
                        "out".
  --binsize=BINSIZE     Size of bins for discordant pairs to run through GASV.
                        The larger the bin size, the larger the region of
                        uncertainty for the breakpoints (which may correspond
                        to alignment uncertainty).  Increasing this binsize
                        will merge clusters.  Default=200.
  --experiment=EXPERIMENT
                        experiment label. Default = "pacbio".
  --lambdad=LAMBDAD     lambda_d for MBSV (corresponds to sequence coverage).
                        Default = 3.0.
  --pseq=PSEQ           probability of an error from sequencing. Default =
                        0.15 (pacbio).
  --keepconcord         Consider multi-breakpoint-mappings from reads that
                        have some concordant alignment.  Warning: this
                        drastically increases the number of multi-breakpoint-
                        mappings, and is not advised for whole-genome
                        analysis.  Default=False.

II(a). Input Files and Output Files #########################################

The main input file is Preprocessor-example/infiles/venter-chr17.m5
 - This file is the first 25,000 lines of the simulated longread data from the Venter chromosome.
This file is very small for a run - typical files are a few Gb.  GitHub allows only 100Mb files.  As a result, the output contains too few multi-breakpoint-mappings to make any sense of it; this is simply used to test that the program is working correctly.

See https://github.com/PacificBiosciences/blasr/wiki/Blasr-Output-Format for information
about m5 and other BLASR formats.

There are many intermediate output files that are generated at various steps.  
They are roughly organized into subdirectories according to the preprocessing step.  
The main output files that are useful for MultiBreak-SV are located in *-MBSVinputs/:
 - assignments.txt: alignment qualities for each multi-breakpoint-mapping
 - experiments.txt: list of experiments (multiple lines if running MultiBreak-SV with 
multiple sequencing experiments)
 - cluster-subproblems/: The GASV clusters file split into independent subproblems. 
Each one can be run as a separate instance of MultiBreakSV.

II(b). Example Run  #########################################################

You must have downloaded GASV and have the local path to GASV.

python bin/M5toMBSV.py --prefix Preprocessor-example/outfiles/out \
       <path_to_GASV>/ lib/ \
       Preprocessor-example/infiles/venter-chr17.m5

The output for this run is in Preprocessor-example/compressed-outfiles/example-output-run.tgz.
 - Console output is in M5toMBSV.out within this directory.

#############################################################################
## III. MultiBreak-SV Usage Instructions ####################################
#############################################################################

MultiBreak-SV takes (i) GASV Clusters, (ii) multi-breakpoint-mapping
alignment qualities, and (iii) parameters for each sequencing platform
and runs a Markov Chain Monte Carlo (MCMC) algorithm that computes the
probability of selecting each multi-breakpoint-mapping given the GASV
clusters.

To print the usage, type 'java -jar bin/MultiBreakSV.jar'. You will see
the following:

MultiBreakSV.java: runs the MultiBreakSV method.

Usage: java -jar bin/MultiBreakSV.jar [ARGUMENTS] [OPTIONAL-ARGUMENTS]

  REQUIRED ARGUMENTS:
  --clusterfile STR	GASV clusters file (run with maximal clusters), 
                        or an "iterations" file output from M5toMBSV.py, 
                        corresponding to an independent set of clusters.

  --assignmentfile STR	File of fragment assignments (with header).
			Column-delimited file where each line denotes a
			single fragment alignment. Columns are
			  1.FragmentID: Unique ID for each sequenced fragment
			  2.DiscordantPairs: discordant pairs that indicate
			    this alignment (these are clustered by GASV)
			  3.NumErrors: number of errors in the alignment
			  4.BasesInAlignment: the number of bases in the
			    alignment (TargetEnd-TargetStart+1)
			  5.ExperimentLabel: name of experiment/platform/run.
			Note that the NumErrors and BasesInAlignment account
			for any concordantly-aligned pairs in the mapping
			(for fragments in particular). BasesInAlignment is the
			sum of the target lengths of the subalignments.

  --experimentfile STR	File of experiments/platforms/runs (with header).
			Column-delimited file where each line denotes a
			single experiment.  Columns are
			  1.ExperimentLabel: name of experiment/platform/run.
			  2.Pseq: sequence error probability (e.g. 0.15 for
			    PacBio, 0.01 for Illumina)
			  3.LambdaD: expected number of fragments to support
			    each SV (e.g. 3 for low-coverage PacBio)
			There are only multiple lines in this file if a hybrid
			experiment is run.

  --numiterations INT	Number of iterations

  --perr FLOAT		Probability that a fragment is unmapped
			(e.g. 0.001)

  OPTIONAL ARGUMENTS:
  --prefix STR		prefix to append to output files. Default is 'out'.

  --matchfile STR	File to initialize MCMC method to. The matchfile
			is a single column of all ESP alignments to be set.
			Default is none.

  --savespace		Does not write mcmc.txt and .samplingprobs files;
			Highly recommended for large problems and/or a large
			number of iterations. Default is false.

  --enumerate		Enumerates all possible combinations and explicitly
			computes each state.  Recommended only for problems
			with < 100states.  Default is false.

  --readclustersfirst	Reads clusters file first rather than
			assignmentsfile. Useful if jobs are split across clusters.
			Default is false.

III(a). Input Files #########################################################

GASV Clusters File (required):
 Clusters file output by GASV.  GASV must be run with no header and
 with "maximal cluster" mode; these are used to establish the cluster
 diagram for MultiBreakSV.  If there are connected components
 (GASV clusters with BP region -1), then they must be listed before
 the maximal clusters.  This file can be split and run in parallel if
 the experiment can be divided into subproblems.

Assignment File (required): 
 File of alignment qualities for all multi-breakpoint-mappings.  Each
 multi-breakpoint-mapping corresponds to a single fragment ID and a
 unique set of discordant pairs.  We count the number of errors (edit
 distance) and the number of bases in the alignments that comprise
 these discordant pairs for each multi-breakpoint-mapping.
 Additionally, we specify the type of experiment (sequencing platform,
 e.g.) to accomodate hybrid runs.  Columns are
	1.FragmentID:	 Unique ID for each sequenced fragment
	2.DiscordantPairs: discordant pairs that indicate
	  this alignment (these are clustered by GASV)
	3.NumErrors: number of errors in the alignment
	4.BasesInAlignment: the number of bases in the
	  alignment (TargetEnd-TargetStart+1)
	5.ExperimentLabel: name of experiment/platform/run.

Experiment File (required):
 File of hyperparameters for each experiment.  If all fragments come
 from a single sequencing experiment, then there is only one line in
 this file.  Columns are
	1.ExperimentLabel: name of experiment/platform/run.
	2.Pseq: sequence error probability (e.g. 0.15 for
	  PacBio, 0.01 for Illumina)
	3.LambdaD: expected number of fragments to support
	  each SV (e.g. 3 for low-coverage PacBio)
 Note that Perr is constant for all sequencing platforms, and so it is
 passed as an argument to MultiBreakSV.

Initial Mapping File (matchfile, optional):
 File of discordant pairs to set as the first mapping of the MCMC
 procedure; this is useful when you want to chain multiple samplings
 together by taking the last mapping from a previous run and
 initialize the next run with it.  This is simply a single-column file
 of discordant pair IDs.

III(b). Output Files #########################################################

FinalAssignment Files:
 These files denote the frequency of sampling each
 multi-breakpoint-mapping, including "none" (which is written as
 'error' in the file).  The columns are
 	 1. StrobeID: the fragment ID
	 2. AssignmentIndex: numerical representation of the
	  multi-breakpoint-mapping (-1 is always error)
	 3. AvgAssignment: Proportion of sampled mappings that contain
	   this multi-breakpoint-mapping
	 4. DiscordantPairs: The discordant pairs in the 
	   multi-breakpoint-mapping.
 There are two FinalAssignment files: the initial sampling
 (AvgAssignment is either 0 or 1) and the final sampling using a long
 burnin.

FinalBreakpoint Files:
 These files denote the frequency of sampling subsets of each cluster
 during the MCMC procedure.  The columns are
 	1. ClusterID: GASV Cluster ID
	2. NumIters: Number of iterations reported
	3-(kmax+3): The number of sampled mappings that contain the
 	  cluster with support i for 0 <= i <= kmax.
There are two FinalBreakpoint files: the initial sampling
 (NumIters=1) and the final sampling using a long burnin.

MCMC.txt File:
 This file reports, for every iteration in the MCMC procedure, the log
 probability, the number of breakpoints, and whether a move was made.
 The columns are
        1. Iteration
	2. Log Prob
	3. NumBreakpoints
	4. MadeMove?

SamplingProbs File:
 This file reports all of the mappings, their sampling probabilities,
 the log probability, and the assignment of all fragments.  The
 columns are
 	 1. SampledProb
	 2. LogProb
	 3: Fragment Assignment (by mapping index)

III(c). Example Runs ##########################################################

The example is from one of the 1000 Genomes simulated experiments.  To run MultiBreak-SV with a random initial mapping:

java -jar bin/MultiBreakSV.jar --clusterfile MultiBreak-SV-example/infiles/gasv.clusters \
     --assignmentfile MultiBreak-SV-example/infiles/assignments.txt \
     --experimentfile MultiBreak-SV-example/infiles/experiments.txt \
     --numiterations 10000 --perr 0.001 --prefix MultiBreak-SV-example/outfiles/multibreaksv-randinit 

To run MultiBreak-SV with a pre-specified initial mapping:

java -jar bin/MultiBreakSV.jar --clusterfile MultiBreak-SV-example/infiles/gasv.clusters \
     --assignmentfile MultiBreak-SV-example/infiles/assignments.txt \
     --experimentfile MultiBreak-SV-example/infiles/experiments.txt \
     --numiterations 10000 --perr 0.001 --prefix MultiBreak-SV-example/outfiles/multibreaksv-setinit \
     --matchfile MultiBreak-SV-example/infiles/initialset.txt

#############################################################################
## IV. Running MultiBreak-SV as Separate Subproblems ########################
#############################################################################

The structure of the GASV clusters in the pre-processing step allow for the
entire space to be divided into independent subproblems.  Briefly, all 
alignments for a particular multi-breakpoint-read must be considered at the
same time, and all clusters that contain these alignments must be considered.
As a result, any other multi-breakpoint-reads in those clusters are also 
considered at the same time.  In practice, there are many ``independent''
clusters, and only a few subproblems that are quite large (often in highly
repetitive regions).  When running MultiBreak-SV, you can change the number
of iterations according to the size of the subproblem.

IV(a). generateIndependentSubproblems.pl Script #############################

This perl script splits the clusters file into independent subproblems.  There
are two required arguments:
(1) clusters file (*.clusters)
(2) output directory

The output directory will be populated with clusters files.
Each file is annotated with the subset/iteration that the
subproblem was determined. 

IV(b). Example Runs #########################################################

To split the GASV clusters file from the example into independent subproblems,
first make the directory to store the new cluster files:

mkdir Preprocessor-example/outfiles/out-independentProbs/

Then run the perl script on the Preprocessor GASV file:

perl bin/generateIndependentSubproblems.pl \
     Preprocessor-example/outfiles/out-RunGASV/gasv.in.clusters \
     Preprocessor-example/outfiles/out-independentProbs/

This will generate 34 subsets, one for each cluster.  The example dataset is
trivial in this case - every cluster is independent.  However, larger datasets
will have indepdent clusters files with multiple lines. For example, running
the perl script on the MultiBreakSV example produces a single independent
cluster:

mkdir MultiBreak-SV-example/infiles/independentProbs/
perl bin/generateIndependentSubproblems.pl \
     MultiBreak-SV-example/infiles/gasv.clusters \
     MultiBreak-SV-example/infiles/independentProbs/

**NOTE:** For this script to work, the longread names must have the prefix
'longread_#' (e.g., longread_1, longread_2, etc.).  If you have a different
naming convention, then you must change the regular expression on L59.

To run one of these subproblems with MultiBreak-SV, you simply replace
the --clusterfile with one of the subproblem names (be sure to also change
the --prefix as well).  You may use the same assignmentfile for each run.
You will get warnings saying that some of the multi-breakpoint-reads don't
appear in the clusters file; this is expected, since you are only running a 
portion of the clusters.

It is faster for MultiBreak-SV to first read the clusters file, since
it is so small, and then only retain the multi-breakpoint-mappings that appear
in these clusters. To do this, also use the --readclustersfirst option.
   
#############################################################################
V. Additional Notes #########################################################
#############################################################################

A. Currently, the software is designed for human chromosomes; these
are either numbered or labeled X or Y.  If you wish to run
MultiBreak-SV with sequence data from another organism, you must first
map the chromosome names to integers.

B. If you have paired-end data (e.g., Illumina) in the form of BAM
files, you can convert the BAM files to endsequence pair (ESP) files
(the inputs to GASV) using the BAM2GASV script provided with GASV.
You then must add these as inputs to GASV along with the
multi-breakpoint-reads so clusters contain a mixture.  You will have
to re-run steps (9) and (10) documented above:
(9) RUNNING GASV
  - Run GASV on the binned ESP files.  Clusters are input to MultiBreak-SV.
(10) SPLITTING CLUSTERS FILE FOR MBSV
  - Divides the gasv.in.clusters file into independent subproblems.  
  - Allows for easy parallelization.

When running GASV, you must modify the GASV input file to also
consider the paired-end ESP file, along with the Lmin/Lmax output by
BAM2GASV.  You will also have to modify the assignment file and the
experiment file that are inputs to MultiBreak-SV.
  - For every end-sequence pair, you must add a line to the assignment
    file.  Note that some of the alignment information may be missing
    from the paired-end sequencing (see C below).
  - Add a single line to the experiment file with different
    probabilities for a sequencing error (e.g., 0.01) and lambda
    (e.g., 10).

C. If you have BLASR alignments in BAM files, some information about
the alignments (the location of mismatches, insertions and deletions)
in the alignments will be missing.  All runs were conducted using m5
files, which contains this information.  We are working on a BAM2MBSV
script that will convert BAM files, adding default values for missing
information.
